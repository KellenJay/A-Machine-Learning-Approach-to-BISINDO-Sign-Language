{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing\n",
        "The dataset was pre-split into training and testing sets for consistency. Only label encoding was performed at this stage, specifically for the benchmark model. Further model-specific preprocessing is described in later sections."
      ],
      "metadata": {
        "id": "KyoTdxZGxSwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kxe9W190ovex",
        "outputId": "607f1619-eecb-458c-9161-e041cbf1b32c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6GxorQqNTb4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.optimizers import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.load('/content/drive/MyDrive/train.npy', allow_pickle=True)\n",
        "X_train = [item['data'] for item in train_data]\n",
        "y_train = [item['label'] for item in train_data]\n",
        "file_name_train = [item['file_name'] for item in train_data]\n",
        "\n",
        "# # Convert to NumPy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "file_name_train = np.array(file_name_train)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of file_name_train:\", file_name_train.shape)\n",
        "\n",
        "test_data = np.load('/content/drive/MyDrive/test.npy', allow_pickle=True)\n",
        "X_test = [item['data'] for item in test_data]\n",
        "y_test = [item['label'] for item in test_data]\n",
        "file_name_test = [item['file_name'] for item in test_data]\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "file_name_test = np.array(file_name_test)\n",
        "\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n",
        "print(\"Shape of file_name_test:\", file_name_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fsl6ZhUNbIq",
        "outputId": "f8d76a30-6727-43d1-c0ed-0c5896b15a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (1185, 113, 225)\n",
            "Shape of y_train: (1185,)\n",
            "Shape of file_name_train: (1185,)\n",
            "Shape of X_test: (60, 113, 225)\n",
            "Shape of y_test: (60,)\n",
            "Shape of file_name_test: (60,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LabelEncoder instance\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the labels\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "# Preserve the y_test in numpy array format\n",
        "y_test_encoded_np = np.array(y_test)\n",
        "\n",
        "# Map original labels to integers\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
      ],
      "metadata": {
        "id": "qv6OanqsHWZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Model (Benchmark)\n",
        "This base model demonstrated the potential of the Transformer architecture for this task. To account for the inherent randomness in neural network training, each model variation, including this base model, was trained three times. The average and standard deviation of key metrics (accuracy, loss, and inference time) were then calculated for comparison.<br>\n",
        "The base model achieved the following results:\n",
        "\n",
        "* Average Training Time: 54.94 seconds ± 1.85 seconds\n",
        "* Average Inference Time: 5.16 seconds ± 0.00 seconds\n",
        "* Average Accuracy: 0.6444 ± 0.0478\n",
        "* Average Loss: 1.8348 ± 0.0670"
      ],
      "metadata": {
        "id": "SkxfzwdAOQ7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "56CXeLyAivLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether GPU available\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFSGvFxtOSz_",
        "outputId": "9ca70f58-25d3-44e7-e9a5-bcf604cccd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transformer_model(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Positional Encoding\n",
        "    positional_encoding = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(tf.range(input_shape[0]))\n",
        "    x = inputs + positional_encoding\n",
        "\n",
        "    # Transformer Encoder\n",
        "    for _ in range(4):  # Number of Transformer blocks\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x + attention_output)\n",
        "        ff_output = layers.Dense(225, activation='relu')(x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x + ff_output)\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "IDFbFr0WOVuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (113, 225)  # (n_frames, n_keypoints * n_coordinates)\n",
        "num_classes = 30\n",
        "val_accuracy_scores = []\n",
        "val_loss_scores = []\n",
        "training_times = []\n",
        "inference_times = []\n",
        "all_predictions = []\n",
        "\n",
        "# Run model training 3 times\n",
        "for i in range(3):\n",
        "    # Instantiate the model\n",
        "    transformer_model = create_transformer_model(input_shape, num_classes)\n",
        "\n",
        "    transformer_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(f\"Training Run {i+1}\")\n",
        "    start_time = time.time()  # Start the timer\n",
        "\n",
        "    history = transformer_model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # End the timer\n",
        "    elapsed_time = end_time - start_time\n",
        "    training_times.append(elapsed_time)\n",
        "    print(f\"Training Time Run {i+1}: {elapsed_time:.2f} seconds\\n\")\n",
        "\n",
        "    print(f\"Inference Run {i+1}\")\n",
        "    start_time = time.time()  # Start the timer\n",
        "\n",
        "    predictions = transformer_model.predict(X_test)\n",
        "\n",
        "    end_time = time.time()  # End the timer\n",
        "    elapsed_time = end_time - start_time\n",
        "    inference_times.append(elapsed_time)\n",
        "    print(f\"Inference Time Run {i+1}: {elapsed_time:.2f} seconds\\n\")\n",
        "    all_predictions.append(predictions)\n",
        "\n",
        "    val_accuracy_scores.append(history.history['val_accuracy'][-1])\n",
        "    val_loss_scores.append(history.history['val_loss'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWvGB8nWr4XD",
        "outputId": "2c2637fa-422a-422c-f224-8d7b80986979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Run 1\n",
            "Epoch 1/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 268ms/step - accuracy: 0.0713 - loss: 3.5374 - val_accuracy: 0.1167 - val_loss: 2.7976\n",
            "Epoch 2/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.1500 - loss: 2.6963 - val_accuracy: 0.3167 - val_loss: 2.4938\n",
            "Epoch 3/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3490 - loss: 1.8920 - val_accuracy: 0.2667 - val_loss: 2.2554\n",
            "Epoch 4/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4449 - loss: 1.4753 - val_accuracy: 0.3667 - val_loss: 2.7555\n",
            "Epoch 5/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4705 - loss: 1.5337 - val_accuracy: 0.3833 - val_loss: 2.0636\n",
            "Epoch 6/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6358 - loss: 0.9607 - val_accuracy: 0.3500 - val_loss: 1.8596\n",
            "Epoch 7/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7113 - loss: 0.7234 - val_accuracy: 0.4000 - val_loss: 1.8531\n",
            "Epoch 8/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8233 - loss: 0.5007 - val_accuracy: 0.4833 - val_loss: 1.6932\n",
            "Epoch 9/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8790 - loss: 0.3619 - val_accuracy: 0.4833 - val_loss: 1.7143\n",
            "Epoch 10/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8521 - loss: 0.4196 - val_accuracy: 0.4333 - val_loss: 2.1188\n",
            "Epoch 11/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8149 - loss: 0.5230 - val_accuracy: 0.5000 - val_loss: 2.0117\n",
            "Epoch 12/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9313 - loss: 0.2181 - val_accuracy: 0.5500 - val_loss: 2.2587\n",
            "Epoch 13/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8553 - loss: 0.4770 - val_accuracy: 0.4000 - val_loss: 1.9500\n",
            "Epoch 14/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9037 - loss: 0.2699 - val_accuracy: 0.5167 - val_loss: 2.2480\n",
            "Epoch 15/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9069 - loss: 0.2580 - val_accuracy: 0.4000 - val_loss: 2.5243\n",
            "Epoch 16/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8194 - loss: 0.5534 - val_accuracy: 0.4167 - val_loss: 2.4967\n",
            "Epoch 17/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8944 - loss: 0.3047 - val_accuracy: 0.4000 - val_loss: 2.5346\n",
            "Epoch 18/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8515 - loss: 0.4766 - val_accuracy: 0.5333 - val_loss: 2.3030\n",
            "Epoch 19/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9280 - loss: 0.2115 - val_accuracy: 0.5833 - val_loss: 1.8987\n",
            "Epoch 20/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9875 - loss: 0.0392 - val_accuracy: 0.6000 - val_loss: 1.8726\n",
            "Epoch 21/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9931 - loss: 0.0290 - val_accuracy: 0.6000 - val_loss: 1.8810\n",
            "Epoch 22/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9617 - loss: 0.1181 - val_accuracy: 0.6500 - val_loss: 1.8245\n",
            "Epoch 23/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9941 - loss: 0.0271 - val_accuracy: 0.6500 - val_loss: 1.6589\n",
            "Epoch 24/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.7000 - val_loss: 1.6521\n",
            "Epoch 25/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.7000 - val_loss: 1.7575\n",
            "Epoch 26/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.7000 - val_loss: 1.7501\n",
            "Epoch 27/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7000 - val_loss: 1.7600\n",
            "Epoch 28/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7000 - val_loss: 1.7751\n",
            "Epoch 29/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.6833 - val_loss: 1.7918\n",
            "Epoch 30/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7000 - val_loss: 1.7904\n",
            "Training Time Run 1: 57.00 seconds\n",
            "\n",
            "Inference Run 1\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step\n",
            "Inference Time Run 1: 5.16 seconds\n",
            "\n",
            "Training Run 2\n",
            "Epoch 1/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 293ms/step - accuracy: 0.0660 - loss: 3.5606 - val_accuracy: 0.0500 - val_loss: 2.8955\n",
            "Epoch 2/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1950 - loss: 2.6364 - val_accuracy: 0.2000 - val_loss: 2.8397\n",
            "Epoch 3/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2183 - loss: 2.4382 - val_accuracy: 0.2167 - val_loss: 2.5444\n",
            "Epoch 4/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3311 - loss: 2.0998 - val_accuracy: 0.3167 - val_loss: 2.1465\n",
            "Epoch 5/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4947 - loss: 1.4458 - val_accuracy: 0.3167 - val_loss: 1.9890\n",
            "Epoch 6/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5518 - loss: 1.2070 - val_accuracy: 0.3667 - val_loss: 2.0801\n",
            "Epoch 7/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6753 - loss: 0.9176 - val_accuracy: 0.3167 - val_loss: 2.3596\n",
            "Epoch 8/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6880 - loss: 0.8595 - val_accuracy: 0.4500 - val_loss: 1.9655\n",
            "Epoch 9/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7791 - loss: 0.5906 - val_accuracy: 0.4667 - val_loss: 2.2279\n",
            "Epoch 10/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7754 - loss: 0.6609 - val_accuracy: 0.5167 - val_loss: 1.9945\n",
            "Epoch 11/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8820 - loss: 0.3438 - val_accuracy: 0.5000 - val_loss: 1.7142\n",
            "Epoch 12/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9191 - loss: 0.2477 - val_accuracy: 0.5500 - val_loss: 2.1859\n",
            "Epoch 13/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8975 - loss: 0.3151 - val_accuracy: 0.5667 - val_loss: 1.8565\n",
            "Epoch 14/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9276 - loss: 0.2001 - val_accuracy: 0.5500 - val_loss: 1.7836\n",
            "Epoch 15/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9572 - loss: 0.1199 - val_accuracy: 0.5667 - val_loss: 1.9243\n",
            "Epoch 16/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9545 - loss: 0.1528 - val_accuracy: 0.5667 - val_loss: 1.9828\n",
            "Epoch 17/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9627 - loss: 0.1308 - val_accuracy: 0.6167 - val_loss: 1.7414\n",
            "Epoch 18/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9343 - loss: 0.2137 - val_accuracy: 0.4500 - val_loss: 2.2717\n",
            "Epoch 19/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9637 - loss: 0.1063 - val_accuracy: 0.6167 - val_loss: 1.6537\n",
            "Epoch 20/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9742 - loss: 0.0802 - val_accuracy: 0.5500 - val_loss: 2.0874\n",
            "Epoch 21/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9583 - loss: 0.1275 - val_accuracy: 0.6833 - val_loss: 1.6264\n",
            "Epoch 22/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9835 - loss: 0.0595 - val_accuracy: 0.5667 - val_loss: 1.6494\n",
            "Epoch 23/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9681 - loss: 0.0860 - val_accuracy: 0.4833 - val_loss: 2.6203\n",
            "Epoch 24/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9380 - loss: 0.1961 - val_accuracy: 0.5667 - val_loss: 2.2128\n",
            "Epoch 25/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9676 - loss: 0.1056 - val_accuracy: 0.5500 - val_loss: 2.2627\n",
            "Epoch 26/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9445 - loss: 0.1595 - val_accuracy: 0.4167 - val_loss: 2.8658\n",
            "Epoch 27/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8636 - loss: 0.3902 - val_accuracy: 0.5500 - val_loss: 1.8870\n",
            "Epoch 28/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9381 - loss: 0.1950 - val_accuracy: 0.4667 - val_loss: 2.4151\n",
            "Epoch 29/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9264 - loss: 0.1804 - val_accuracy: 0.6000 - val_loss: 1.9696\n",
            "Epoch 30/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9658 - loss: 0.0965 - val_accuracy: 0.5833 - val_loss: 1.9295\n",
            "Training Time Run 2: 55.30 seconds\n",
            "\n",
            "Inference Run 2\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
            "Inference Time Run 2: 5.17 seconds\n",
            "\n",
            "Training Run 3\n",
            "Epoch 1/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 266ms/step - accuracy: 0.0662 - loss: 3.6949 - val_accuracy: 0.1167 - val_loss: 2.8408\n",
            "Epoch 2/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1710 - loss: 2.6543 - val_accuracy: 0.2333 - val_loss: 2.4125\n",
            "Epoch 3/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3213 - loss: 2.0398 - val_accuracy: 0.1333 - val_loss: 2.7476\n",
            "Epoch 4/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3270 - loss: 2.0551 - val_accuracy: 0.3500 - val_loss: 2.0439\n",
            "Epoch 5/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4776 - loss: 1.4451 - val_accuracy: 0.3667 - val_loss: 2.0453\n",
            "Epoch 6/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6355 - loss: 0.9754 - val_accuracy: 0.4167 - val_loss: 1.8382\n",
            "Epoch 7/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7344 - loss: 0.7209 - val_accuracy: 0.4833 - val_loss: 1.9460\n",
            "Epoch 8/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8354 - loss: 0.4644 - val_accuracy: 0.2667 - val_loss: 3.0828\n",
            "Epoch 9/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5054 - loss: 1.8190 - val_accuracy: 0.4000 - val_loss: 1.7257\n",
            "Epoch 10/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7601 - loss: 0.6998 - val_accuracy: 0.5333 - val_loss: 1.4967\n",
            "Epoch 11/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9019 - loss: 0.3070 - val_accuracy: 0.4500 - val_loss: 1.8365\n",
            "Epoch 12/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9119 - loss: 0.2837 - val_accuracy: 0.6000 - val_loss: 1.6574\n",
            "Epoch 13/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9122 - loss: 0.3216 - val_accuracy: 0.5500 - val_loss: 1.9833\n",
            "Epoch 14/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9288 - loss: 0.2234 - val_accuracy: 0.5333 - val_loss: 1.6867\n",
            "Epoch 15/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9530 - loss: 0.1736 - val_accuracy: 0.6167 - val_loss: 1.8216\n",
            "Epoch 16/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9882 - loss: 0.0595 - val_accuracy: 0.6167 - val_loss: 1.5548\n",
            "Epoch 17/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9988 - loss: 0.0177 - val_accuracy: 0.6167 - val_loss: 1.6361\n",
            "Epoch 18/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9814 - loss: 0.0666 - val_accuracy: 0.4667 - val_loss: 2.5653\n",
            "Epoch 19/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7339 - loss: 0.9716 - val_accuracy: 0.5333 - val_loss: 2.1029\n",
            "Epoch 20/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8394 - loss: 0.4498 - val_accuracy: 0.5500 - val_loss: 1.6159\n",
            "Epoch 21/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9800 - loss: 0.1108 - val_accuracy: 0.6333 - val_loss: 1.4458\n",
            "Epoch 22/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9782 - loss: 0.0811 - val_accuracy: 0.6000 - val_loss: 1.6714\n",
            "Epoch 23/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9733 - loss: 0.1029 - val_accuracy: 0.6167 - val_loss: 1.3958\n",
            "Epoch 24/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9872 - loss: 0.0740 - val_accuracy: 0.5333 - val_loss: 1.7658\n",
            "Epoch 25/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.6167 - val_loss: 1.7120\n",
            "Epoch 26/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.6333 - val_loss: 1.7428\n",
            "Epoch 27/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.6333 - val_loss: 1.7527\n",
            "Epoch 28/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6167 - val_loss: 1.7732\n",
            "Epoch 29/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6500 - val_loss: 1.7867\n",
            "Epoch 30/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.6500 - val_loss: 1.7845\n",
            "Training Time Run 3: 52.51 seconds\n",
            "\n",
            "Inference Run 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fc2b8c5add0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fc2b8c5add0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
            "Inference Time Run 3: 5.17 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "jFWFCCj5eL_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_and_print_metrics(training_times, inference_times, val_accuracy_scores, val_loss_scores):\n",
        "    # Compute average and standard deviation\n",
        "    avg_training_time = np.mean(training_times)\n",
        "    std_training_time = np.std(training_times)\n",
        "    avg_inference_time = np.mean(inference_times)\n",
        "    std_inference_time = np.std(inference_times)\n",
        "    avg_accuracy = np.mean(val_accuracy_scores)\n",
        "    std_accuracy = np.std(val_accuracy_scores)\n",
        "    avg_loss = np.mean(val_loss_scores)\n",
        "    std_loss = np.std(val_loss_scores)\n",
        "\n",
        "    print(f\"Average Training Time: {avg_training_time:.2f} seconds, Std Deviation {std_training_time:.2f} seconds\")\n",
        "    print(f\"Average Inference Time: {avg_inference_time:.2f} seconds, Std Deviation {std_inference_time:.2f} seconds\")\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.4f}, Std Dev: {std_accuracy:.4f}\")\n",
        "    print(f\"Average Loss: {avg_loss:.4f}, Std Dev: {std_loss:.4f}\")"
      ],
      "metadata": {
        "id": "I67V6uIcqPbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_and_print_metrics(training_times, inference_times, val_accuracy_scores, val_loss_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5aLXjuZvzXx",
        "outputId": "742471e2-1de0-424f-ef89-77a42352be74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Time: 54.94 seconds, Std Deviation 1.85 seconds\n",
            "Average Inference Time: 5.16 seconds, Std Deviation 0.00 seconds\n",
            "Average Accuracy: 0.6444, Std Dev: 0.0478\n",
            "Average Loss: 1.8348, Std Dev: 0.0670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Misclassified Labels"
      ],
      "metadata": {
        "id": "65XZeCsq-kLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_misclassified_dataframe(all_predictions, label_mapping, y_test):\n",
        "\n",
        "    # Convert to integer labels\n",
        "    int_predictions = [np.argmax(p, axis=1) for p in all_predictions]\n",
        "    # Stack predictions for each run\n",
        "    stacked_predictions = np.array(int_predictions)  # Shape: (3, n_samples)\n",
        "    # Majority vote\n",
        "    final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=stacked_predictions)\n",
        "\n",
        "    # Reverse the dictionary\n",
        "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "    # Get the misclassified index\n",
        "    wrong_indices = np.where(final_predictions != y_test)[0]\n",
        "    # Create a DataFrame for misclassified samples\n",
        "    misclassified_df = pd.DataFrame({\n",
        "        \"Test Index\": wrong_indices,\n",
        "        \"True Label\": [reverse_label_mapping[y_test[i]] for i in wrong_indices],\n",
        "        \"Predicted Label\": [reverse_label_mapping[final_predictions[i]] for i in wrong_indices],\n",
        "        \"File Name\": [file_name_test[i] for i in wrong_indices]\n",
        "    })\n",
        "    return misclassified_df"
      ],
      "metadata": {
        "id": "t4cvkHRbmrJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "misclassified_df = get_misclassified_dataframe(all_predictions, label_mapping, y_test)\n",
        "print(misclassified_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erLwuvJHwoL6",
        "outputId": "9dcad9c3-cc0c-4e1e-f0ea-d255d80134d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Test Index True Label Predicted Label       File Name\n",
            "0            2      teman         panggil    teman_07.npy\n",
            "1            3      teman            guru    teman_09.npy\n",
            "2            8    sedikit            anak  sedikit_01.npy\n",
            "3           20      marah          kertas    marah_09.npy\n",
            "4           22      makan           minum    makan_04.npy\n",
            "5           23      makan           minum    makan_09.npy\n",
            "6           25       main         gembira     main_10.npy\n",
            "7           27       maaf             ibu     maaf_09.npy\n",
            "8           28      lihat             ibu    lihat_04.npy\n",
            "9           29      lihat            haus    lihat_07.npy\n",
            "10          31      lapar            anak    lapar_07.npy\n",
            "11          33     kucing         gembira   kucing_10.npy\n",
            "12          34     kertas            main   kertas_01.npy\n",
            "13          35     kertas            main   kertas_03.npy\n",
            "14          39      jalan            anak    jalan_09.npy\n",
            "15          41        ibu          dengar      ibu_03.npy\n",
            "16          44      besar           marah    besar_05.npy\n",
            "17          51       anak           buruk     anak_10.npy\n",
            "18          57     dengar             ibu   dengar_04.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models Variation"
      ],
      "metadata": {
        "id": "4HzvzznjOw1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model A\n",
        "\n",
        "Building upon the base model, eight key improvements were implemented in Model A. These improvements focused on three main areas: input preprocessing (addition of keypoint angles, standardization of coordinates, label smoothing), Transformer architecture (pre-normalization, increased attention heads, and additional feedforward layers), and compiler settings/training strategy (weight decay, dynamic learning rate scheduling, varied batch sizes, and early stopping).<br>\n",
        "The Model A achieved the following results:\n",
        "\n",
        "* Average Training Time: 56.12 seconds ± 8.12 seconds\n",
        "* Average Inference Time: 6.93 seconds ± 2.37 seconds\n",
        "* Average Accuracy: 0.8000 ± 0.0471\n",
        "* Average Loss: 1.3277 ± 0.0903"
      ],
      "metadata": {
        "id": "B3dnPkH6VaCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate the angle between three points (A, B, C)\n",
        "def calculate_angle(A, B, C):\n",
        "    BA = A - B\n",
        "    BC = C - B\n",
        "    # Compute dot product and magnitudes\n",
        "    dot_product = np.dot(BA, BC)\n",
        "    magnitude_BA = np.linalg.norm(BA)\n",
        "    magnitude_BC = np.linalg.norm(BC)\n",
        "    # Prevent division by zero\n",
        "    if magnitude_BA == 0 or magnitude_BC == 0:\n",
        "        return 0.0\n",
        "    # Calculate the cosine of the angle\n",
        "    cos_angle = dot_product / (magnitude_BA * magnitude_BC)\n",
        "    # Clip values to handle numerical errors\n",
        "    cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
        "    # Return the angle in radians\n",
        "    return np.arccos(cos_angle)"
      ],
      "metadata": {
        "id": "CJkjSVwbNfsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(X):\n",
        "    # Reshape the data into (n_videos, n_frames, n_keypoints, 3)\n",
        "    n_videos, n_frames, n_features = X.shape\n",
        "    n_keypoints = 75\n",
        "    X_reshaped = X.reshape(n_videos, n_frames, n_keypoints, 3)\n",
        "\n",
        "    # Define keypoints for angle calculation (indices start from 0)\n",
        "    pose_angle_indices = [\n",
        "        (12, 14, 16),\n",
        "        (14, 16, 18),\n",
        "        (18, 16, 22),\n",
        "        (14, 12, 24),\n",
        "\n",
        "        (11, 13, 15),\n",
        "        (13, 15, 17),\n",
        "        (17, 15, 21),\n",
        "        (13, 11, 23),\n",
        "    ]\n",
        "    # For both left and right hands\n",
        "    hand_angle_indices = [(4, 0, 8),\n",
        "                          (8, 0, 16),\n",
        "                          (0, 9, 12),\n",
        "                          (0, 17,20),\n",
        "                          ]\n",
        "\n",
        "    # Calculate angles for each video and frame\n",
        "    angles_list = []\n",
        "    for video in X_reshaped:\n",
        "        video_angles = []\n",
        "        for frame in video:\n",
        "            frame_angles = []\n",
        "            # Pose angles\n",
        "            for (i, j, k) in pose_angle_indices:\n",
        "                frame_angles.append(calculate_angle(frame[i], frame[j], frame[k]))\n",
        "            # Left hand angles\n",
        "            for (i, j, k) in hand_angle_indices:\n",
        "                frame_angles.append(calculate_angle(frame[33 + i], frame[33 + j], frame[33 + k]))\n",
        "            # Right hand angles\n",
        "            for (i, j, k) in hand_angle_indices:\n",
        "                frame_angles.append(calculate_angle(frame[54 + i], frame[54 + j], frame[54 + k]))\n",
        "            video_angles.append(frame_angles)\n",
        "        angles_list.append(video_angles)\n",
        "\n",
        "    # Convert angles list to a numpy array\n",
        "    angles_array = np.array(angles_list)  # Shape: (n_videos, n_frames, n_angles)\n",
        "    return angles_array"
      ],
      "metadata": {
        "id": "yB_i4yqwNhQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get joint angles\n",
        "X_train_angles = get_angles(X_train)\n",
        "X_test_angles = get_angles(X_test)"
      ],
      "metadata": {
        "id": "Dk2tgpyeAWQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_labels(y_true, num_classes, smoothing=0.1):\n",
        "    # Convert to one-hot\n",
        "    y_true_one_hot = tf.one_hot(y_true, depth=num_classes)\n",
        "    # Apply smoothing\n",
        "    smoothed_labels = y_true_one_hot * (1 - smoothing) + (smoothing / num_classes)\n",
        "    return smoothed_labels"
      ],
      "metadata": {
        "id": "U29adkPulRZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply label smoothing to the training labels.\n",
        "num_classes = 30 # Number of classes in dataset\n",
        "label_smoothing = 0.1 # Smoothing parameter\n",
        "y_train_smoothed = smooth_labels(y_train, num_classes, smoothing=label_smoothing)\n",
        "\n",
        "# Convert y_test into one-hot format too, for consistency. We don't smooth the test labels.\n",
        "y_test = tf.one_hot(y_test, depth=num_classes)"
      ],
      "metadata": {
        "id": "RYoI2MOZN7CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create normalization layer. Standardization is performed per frame (axis=-1).\n",
        "normalization_layer = layers.Normalization(axis=-1)\n",
        "\n",
        "# Adapt the normalization layer to the training data to calculate mean and std\n",
        "normalization_layer.adapt(X_train)\n",
        "\n",
        "# Standardize the data\n",
        "X_train_standardized = normalization_layer(X_train).numpy()\n",
        "X_test_standardized = normalization_layer(X_test).numpy()\n",
        "\n",
        "# Add angle features to the standardized landmark data.\n",
        "X_train = np.concatenate([X_train_standardized, X_train_angles],axis=-1)\n",
        "X_test = np.concatenate([X_test_standardized, X_test_angles],axis=-1)\n",
        "\n",
        "# Convert to TensorFlow tensor\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "y_train = tf.convert_to_tensor(y_train_smoothed, dtype=tf.float32)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "rDT3nzB5AtKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transformer_model(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Positional Encoding\n",
        "    positional_encoding = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(tf.range(input_shape[0]))\n",
        "    x = inputs + positional_encoding\n",
        "\n",
        "    # Transformer Encoder\n",
        "    for _ in range(4):  # Number of Transformer blocks\n",
        "        # Normalized before attention, instead of after\n",
        "        x_norm = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        # Instead of 4 (base), 8 used\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=8, key_dim=64)(x_norm, x_norm)\n",
        "        x = x + attention_output\n",
        "        # Instead of a single layer with 241 units, added 1 denser layer.\n",
        "        ff_output = layers.Dense(512, activation='relu')(x)\n",
        "        ff_output = layers.Dense(241, activation='relu')(x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x + ff_output)\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "3l2eMsMVOFVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (113, 241)  # (n_frames, n_keypoints * n_coordinates)\n",
        "num_classes = 30\n",
        "val_accuracy_scores = []\n",
        "val_loss_scores = []\n",
        "training_times = []\n",
        "inference_times = []\n",
        "all_predictions = []\n",
        "\n",
        "# Run model training 3 times\n",
        "for i in range(3):\n",
        "    # Instantiate the model\n",
        "    transformer_model = create_transformer_model(input_shape, num_classes)\n",
        "\n",
        "    # Define weight decay\n",
        "    weight_decay = 1e-4  # Can adjust this value (e.g., 1e-3, 5e-5)\n",
        "\n",
        "    # Compile the model\n",
        "    transformer_model.compile(\n",
        "        optimizer=AdamW(learning_rate=0.001, weight_decay=weight_decay),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # Add the learning rate scheduler callback\n",
        "    lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "    # Add early stopping callback\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    # Combine Callbacks\n",
        "    callbacks = [lr_callback, early_stopping]\n",
        "    print(f\"Training Run {i+1}\")\n",
        "    start_time = time.time()  # Start the timer\n",
        "\n",
        "    history = transformer_model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        callbacks=[callbacks]\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # End the timer\n",
        "    elapsed_time = end_time - start_time\n",
        "    training_times.append(elapsed_time)\n",
        "    print(f\"Training Time Run {i+1}: {elapsed_time:.2f} seconds\\n\")\n",
        "\n",
        "    print(f\"Inference Run {i+1}\")\n",
        "    start_time = time.time()  # Start the timer\n",
        "\n",
        "    predictions = transformer_model.predict(X_test)  # Replace x_test with your test data\n",
        "\n",
        "    end_time = time.time()  # End the timer\n",
        "    elapsed_time = end_time - start_time\n",
        "    inference_times.append(elapsed_time)\n",
        "    print(f\"Inference Time Run {i+1}: {elapsed_time:.2f} seconds\\n\")\n",
        "    all_predictions.append(predictions)\n",
        "\n",
        "    val_accuracy_scores.append(history.history['val_accuracy'][-1])\n",
        "    val_loss_scores.append(history.history['val_loss'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teBiu3nx_Qhg",
        "outputId": "a3847d20-9614-4963-a5c1-bbe13c8c73f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Run 1\n",
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 470ms/step - accuracy: 0.2519 - loss: 2.9809 - val_accuracy: 0.4833 - val_loss: 2.1019 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7784 - loss: 1.3041 - val_accuracy: 0.6333 - val_loss: 1.7323 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9338 - loss: 0.9447 - val_accuracy: 0.6667 - val_loss: 1.6458 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9493 - loss: 0.8747 - val_accuracy: 0.7500 - val_loss: 1.4285 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9766 - loss: 0.7877 - val_accuracy: 0.7667 - val_loss: 1.4207 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9936 - loss: 0.7114 - val_accuracy: 0.7667 - val_loss: 1.4185 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.6879 - val_accuracy: 0.7333 - val_loss: 1.4745 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.6725 - val_accuracy: 0.8000 - val_loss: 1.2962 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6591 - val_accuracy: 0.8333 - val_loss: 1.3229 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.6554 - val_accuracy: 0.8000 - val_loss: 1.3112 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6534 - val_accuracy: 0.8167 - val_loss: 1.3118 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6507 - val_accuracy: 0.8500 - val_loss: 1.3035 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6495 - val_accuracy: 0.8333 - val_loss: 1.3115 - learning_rate: 5.0000e-04\n",
            "Training Time Run 1: 52.49 seconds\n",
            "\n",
            "Inference Run 1\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step\n",
            "Inference Time Run 1: 10.28 seconds\n",
            "\n",
            "Training Run 2\n",
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 374ms/step - accuracy: 0.2857 - loss: 2.9967 - val_accuracy: 0.4833 - val_loss: 2.1132 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6998 - loss: 1.4501 - val_accuracy: 0.6500 - val_loss: 1.8349 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8862 - loss: 1.0702 - val_accuracy: 0.5167 - val_loss: 1.8133 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9215 - loss: 0.9533 - val_accuracy: 0.6833 - val_loss: 1.4926 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9757 - loss: 0.7911 - val_accuracy: 0.7833 - val_loss: 1.3125 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9970 - loss: 0.7100 - val_accuracy: 0.8000 - val_loss: 1.2502 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6763 - val_accuracy: 0.8500 - val_loss: 1.2139 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.6646 - val_accuracy: 0.8500 - val_loss: 1.2180 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6617 - val_accuracy: 0.8333 - val_loss: 1.2212 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6573 - val_accuracy: 0.8167 - val_loss: 1.2044 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6542 - val_accuracy: 0.8167 - val_loss: 1.2211 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6564 - val_accuracy: 0.8333 - val_loss: 1.2347 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.6525 - val_accuracy: 0.8167 - val_loss: 1.2255 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6498 - val_accuracy: 0.8333 - val_loss: 1.2235 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.6491 - val_accuracy: 0.8333 - val_loss: 1.2261 - learning_rate: 5.0000e-04\n",
            "Training Time Run 2: 48.49 seconds\n",
            "\n",
            "Inference Run 2\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n",
            "Inference Time Run 2: 5.36 seconds\n",
            "\n",
            "Training Run 3\n",
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 346ms/step - accuracy: 0.3118 - loss: 2.8145 - val_accuracy: 0.4167 - val_loss: 2.0072 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - accuracy: 0.7898 - loss: 1.3053 - val_accuracy: 0.6333 - val_loss: 1.6986 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9138 - loss: 0.9953 - val_accuracy: 0.6333 - val_loss: 1.5796 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9792 - loss: 0.8112 - val_accuracy: 0.7167 - val_loss: 1.4447 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9955 - loss: 0.7227 - val_accuracy: 0.6833 - val_loss: 1.4621 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9963 - loss: 0.6970 - val_accuracy: 0.7500 - val_loss: 1.4110 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6715 - val_accuracy: 0.7333 - val_loss: 1.3953 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6620 - val_accuracy: 0.7833 - val_loss: 1.3934 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.6575 - val_accuracy: 0.8167 - val_loss: 1.3796 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.6650 - val_accuracy: 0.7833 - val_loss: 1.4331 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9939 - loss: 0.6856 - val_accuracy: 0.6333 - val_loss: 1.7838 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9697 - loss: 0.7860 - val_accuracy: 0.7167 - val_loss: 1.5394 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9737 - loss: 0.7888 - val_accuracy: 0.7333 - val_loss: 1.4816 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.6877 - val_accuracy: 0.7333 - val_loss: 1.4456 - learning_rate: 5.0000e-04\n",
            "Training Time Run 3: 67.37 seconds\n",
            "\n",
            "Inference Run 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fb91b69cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2s/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fb91b69cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
            "Inference Time Run 3: 5.15 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "EPSSF7KgeQca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_and_print_metrics(training_times, inference_times, val_accuracy_scores, val_loss_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q34k6IsBCImz",
        "outputId": "074e4208-66f2-4afd-83ba-e3fcf678f6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Time: 56.12 seconds, Std Deviation 8.12 seconds\n",
            "Average Inference Time: 6.93 seconds, Std Deviation 2.37 seconds\n",
            "Average Accuracy: 0.8000, Std Dev: 0.0471\n",
            "Average Loss: 1.3277, Std Dev: 0.0903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Misclassified Labels"
      ],
      "metadata": {
        "id": "-J5VtsqDlsRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "misclassified_df = get_misclassified_dataframe(all_predictions, label_mapping, y_test)\n",
        "print(misclassified_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yj9FofMCONf",
        "outputId": "e3bf5a69-89ce-46cd-d399-a74ba51a2cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Test Index True Label Predicted Label       File Name\n",
            "0            5     senyum           lihat   senyum_07.npy\n",
            "1            8    sedikit           orang  sedikit_01.npy\n",
            "2           14      orang            adik    orang_02.npy\n",
            "3           15      orang            adik    orang_04.npy\n",
            "4           22      makan           minum    makan_04.npy\n",
            "5           28      lihat           makan    lihat_04.npy\n",
            "6           34     kertas            main   kertas_01.npy\n",
            "7           39      jalan        keluarga    jalan_09.npy\n",
            "8           50       anak           orang     anak_03.npy\n",
            "9           56     dengar             ibu   dengar_02.npy\n",
            "10          57     dengar             ibu   dengar_04.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model B\n",
        "Model B builds upon the architecture and preprocessing steps of Model A but incorporates hyperparameter tuning using Keras Tuner. This automated search explored different combinations of hyperparameters to optimize model performance. The tuning process and the resulting best hyperparameters are detailed below.\n",
        "\n",
        "The final Model B achieved the following results:\n",
        "\n",
        "* Average Training Time: 85.06 seconds ± 16.41 seconds\n",
        "* Average Inference Time: 6.86 seconds ± 2.41 seconds\n",
        "* Average Accuracy: 0.8333 ± 0.0136\n",
        "* Average Loss: 1.1957 ± 0.0115"
      ],
      "metadata": {
        "id": "nS9sA7chXuWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "1vW26pfJCpqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q keras-tuner"
      ],
      "metadata": {
        "id": "HCg9OUh7Xt4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "\n",
        "# Define the HyperModel\n",
        "def build_transformer_model(hp):\n",
        "    input_shape = (113, 241)  # (n_frames, n_keypoints * n_coordinates + n_angles)\n",
        "    num_classes = 30\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Positional Encoding\n",
        "    positional_encoding = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(tf.range(input_shape[0]))\n",
        "    x = inputs + positional_encoding\n",
        "\n",
        "    # Hyperparameter tuning for number of Transformer blocks\n",
        "    for _ in range(hp.Int(\"num_blocks\", 2, 6, step=1)):  # 2 to 6 blocks\n",
        "        x_norm = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        attention_heads = hp.Choice(\"num_heads\", [4, 8, 12])  # Choose between 4, 8, 12 heads\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=attention_heads,\n",
        "            key_dim=hp.Choice(\"key_dim\", [32, 64, 128]))(x_norm, x_norm)\n",
        "        x = x + attention_output\n",
        "\n",
        "        # Feed Forward Network\n",
        "        ff_units = hp.Int(\"ff_units\", min_value=128, max_value=512, step=128)  # Units in FF layers\n",
        "        ff_output = layers.Dense(ff_units, activation='relu')(x)\n",
        "        ff_output = layers.Dense(241, activation='relu')(ff_output)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x + ff_output)\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    # Define optimizer with weight decay\n",
        "    weight_decay = hp.Choice(\"weight_decay\", [1e-4, 5e-5, 1e-5])\n",
        "    learning_rate = hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])\n",
        "    optimizer = AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Instantiate the tuner\n",
        "tuner = kt.BayesianOptimization(\n",
        "    build_transformer_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,  # Number of combinations to try\n",
        "    directory=\"transformer_tuning\",  # Directory to save results\n",
        "    project_name=\"hyperparam_tuning\"\n",
        ")\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "# Get the best model\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(f\"Number of Transformer Blocks: {best_hps.get('num_blocks')}\")\n",
        "print(f\"Number of Attention Heads: {best_hps.get('num_heads')}\")\n",
        "print(f\"Key Dimension: {best_hps.get('key_dim')}\")\n",
        "print(f\"Feed Forward Units: {best_hps.get('ff_units')}\")\n",
        "print(f\"Learning Rate: {best_hps.get('learning_rate')}\")\n",
        "print(f\"Weight Decay: {best_hps.get('weight_decay')}\")\n",
        "\n",
        "# Train the best model\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aK8mgKVYB_P",
        "outputId": "07a063fa-2630-48db-8315-5089a6266115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 01m 42s]\n",
            "val_accuracy: 0.8666666746139526\n",
            "\n",
            "Best val_accuracy So Far: 0.8666666746139526\n",
            "Total elapsed time: 00h 14m 18s\n",
            "Best Hyperparameters:\n",
            "Number of Transformer Blocks: 4\n",
            "Number of Attention Heads: 8\n",
            "Key Dimension: 128\n",
            "Feed Forward Units: 512\n",
            "Learning Rate: 0.001\n",
            "Weight Decay: 0.0001\n",
            "Epoch 1/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 410ms/step - accuracy: 0.1863 - loss: 3.4616 - val_accuracy: 0.3833 - val_loss: 2.3189\n",
            "Epoch 2/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.5221 - loss: 1.9046 - val_accuracy: 0.3667 - val_loss: 2.1475\n",
            "Epoch 3/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.7263 - loss: 1.3797 - val_accuracy: 0.5667 - val_loss: 1.8893\n",
            "Epoch 4/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.8264 - loss: 1.1513 - val_accuracy: 0.5667 - val_loss: 1.5722\n",
            "Epoch 5/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9242 - loss: 0.9441 - val_accuracy: 0.7000 - val_loss: 1.3779\n",
            "Epoch 6/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9703 - loss: 0.7899 - val_accuracy: 0.7833 - val_loss: 1.3386\n",
            "Epoch 7/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9835 - loss: 0.7429 - val_accuracy: 0.7833 - val_loss: 1.3183\n",
            "Epoch 8/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9963 - loss: 0.6885 - val_accuracy: 0.8000 - val_loss: 1.2505\n",
            "Epoch 9/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6690 - val_accuracy: 0.8000 - val_loss: 1.2946\n",
            "Epoch 10/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6578 - val_accuracy: 0.8167 - val_loss: 1.2572\n",
            "Epoch 11/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6539 - val_accuracy: 0.8167 - val_loss: 1.2481\n",
            "Epoch 12/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6508 - val_accuracy: 0.8167 - val_loss: 1.2666\n",
            "Epoch 13/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6500 - val_accuracy: 0.8333 - val_loss: 1.2541\n",
            "Epoch 14/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6482 - val_accuracy: 0.8167 - val_loss: 1.2386\n",
            "Epoch 15/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6477 - val_accuracy: 0.8167 - val_loss: 1.2462\n",
            "Epoch 16/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6468 - val_accuracy: 0.8333 - val_loss: 1.2387\n",
            "Epoch 17/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6461 - val_accuracy: 0.8333 - val_loss: 1.2465\n",
            "Epoch 18/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6458 - val_accuracy: 0.8333 - val_loss: 1.2366\n",
            "Epoch 19/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6455 - val_accuracy: 0.8000 - val_loss: 1.2327\n",
            "Epoch 20/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6454 - val_accuracy: 0.8333 - val_loss: 1.2428\n",
            "Epoch 21/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6452 - val_accuracy: 0.8333 - val_loss: 1.2273\n",
            "Epoch 22/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6449 - val_accuracy: 0.8167 - val_loss: 1.2358\n",
            "Epoch 23/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6450 - val_accuracy: 0.8167 - val_loss: 1.2364\n",
            "Epoch 24/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6448 - val_accuracy: 0.8167 - val_loss: 1.2298\n",
            "Epoch 25/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6460 - val_accuracy: 0.8333 - val_loss: 1.2051\n",
            "Epoch 26/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6455 - val_accuracy: 0.8167 - val_loss: 1.2111\n",
            "Epoch 27/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6452 - val_accuracy: 0.8000 - val_loss: 1.2170\n",
            "Epoch 28/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6445 - val_accuracy: 0.7833 - val_loss: 1.2049\n",
            "Epoch 29/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6443 - val_accuracy: 0.8000 - val_loss: 1.2276\n",
            "Epoch 30/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6442 - val_accuracy: 0.8000 - val_loss: 1.2151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building with Best Parameter\n",
        "\n",
        "Best Hyperparameters:\n",
        "* Number of Transformer Blocks: 4\n",
        "* Number of Attention Heads: 8\n",
        "* Key Dimension: 128\n",
        "* Feed Forward Units: 512\n",
        "* Learning Rate: 0.001\n",
        "* Weight Decay: 0.0001\n",
        "\n",
        "The only hyperparameter change in Model B compared to Model A was the key dimension, which was increased from 64 to 128."
      ],
      "metadata": {
        "id": "IPpAZf8OC8Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transformer_model(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Positional Encoding\n",
        "    positional_encoding = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(tf.range(input_shape[0]))\n",
        "    x = inputs + positional_encoding\n",
        "\n",
        "    # Transformer Encoder\n",
        "    for _ in range(4):  # Number of Transformer blocks\n",
        "        # Layer Normalization (applied before attention, based on prior experimentation)\n",
        "        x_norm = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        # Multi-Head Attention (8 heads, increased key dimension to 128 from base 64)\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=8, key_dim=128)(x_norm, x_norm)\n",
        "        x = x + attention_output\n",
        "        # Feed-Forward Network (added an extra dense layer with 512 units based on prior experimentation)\n",
        "        ff_output = layers.Dense(512, activation='relu')(x)\n",
        "        ff_output = layers.Dense(241, activation='relu')(x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x + ff_output)\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "Zb9rwyTjC7oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (113, 241)  # (n_frames, n_keypoints * n_coordinates)\n",
        "num_classes = 30\n",
        "val_accuracy_scores = []\n",
        "val_loss_scores = []\n",
        "training_times = []\n",
        "inference_times = []\n",
        "all_predictions = []\n",
        "\n",
        "# Run model training 3 times\n",
        "for i in range(3):\n",
        "    # Instantiate the model\n",
        "    transformer_model = create_transformer_model(input_shape, num_classes)\n",
        "\n",
        "    # Define weight decay\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    # Compile the model\n",
        "    transformer_model.compile(\n",
        "        optimizer=AdamW(learning_rate=0.001, weight_decay=weight_decay),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # Add the learning rate scheduler callback\n",
        "    lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "    # Add early stopping callback\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    # Combine Callbacks\n",
        "    callbacks = [lr_callback, early_stopping]\n",
        "    print(f\"Training Run {i+1}\")\n",
        "    start_time = time.time()  # Start the timer\n",
        "\n",
        "    history = transformer_model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        callbacks=[callbacks]\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # End the timer\n",
        "    elapsed_time = end_time - start_time\n",
        "    training_times.append(elapsed_time)\n",
        "    print(f\"Training Time Run {i+1}: {elapsed_time:.2f} seconds\\n\")\n",
        "\n",
        "    print(f\"Inference Run {i+1}\")\n",
        "    start_time = time.time()  # Start the timer\n",
        "\n",
        "    predictions = transformer_model.predict(X_test)  # Replace x_test with your test data\n",
        "\n",
        "    end_time = time.time()  # End the timer\n",
        "    elapsed_time = end_time - start_time\n",
        "    inference_times.append(elapsed_time)\n",
        "    print(f\"Inference Time Run {i+1}: {elapsed_time:.2f} seconds\\n\")\n",
        "    all_predictions.append(predictions)\n",
        "\n",
        "    val_accuracy_scores.append(history.history['val_accuracy'][-1])\n",
        "    val_loss_scores.append(history.history['val_loss'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOzFqCcyDuhK",
        "outputId": "fcf76e32-8472-4e9c-b28f-7b16192816cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Run 1\n",
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 357ms/step - accuracy: 0.2308 - loss: 3.1903 - val_accuracy: 0.4500 - val_loss: 2.2628 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.5944 - loss: 1.7017 - val_accuracy: 0.5000 - val_loss: 1.8774 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8134 - loss: 1.2227 - val_accuracy: 0.5167 - val_loss: 1.7587 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9252 - loss: 0.9944 - val_accuracy: 0.5667 - val_loss: 1.7356 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8812 - loss: 1.1006 - val_accuracy: 0.6833 - val_loss: 1.6056 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9711 - loss: 0.8381 - val_accuracy: 0.7167 - val_loss: 1.5421 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9766 - loss: 0.7828 - val_accuracy: 0.7833 - val_loss: 1.3439 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9984 - loss: 0.6943 - val_accuracy: 0.8000 - val_loss: 1.2682 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6670 - val_accuracy: 0.8167 - val_loss: 1.2281 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6592 - val_accuracy: 0.8167 - val_loss: 1.2278 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6549 - val_accuracy: 0.8000 - val_loss: 1.2205 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6527 - val_accuracy: 0.8167 - val_loss: 1.2159 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6513 - val_accuracy: 0.8000 - val_loss: 1.2108 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6496 - val_accuracy: 0.8333 - val_loss: 1.1906 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.6487 - val_accuracy: 0.8333 - val_loss: 1.2016 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6480 - val_accuracy: 0.8333 - val_loss: 1.1957 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6499 - val_accuracy: 0.8333 - val_loss: 1.1950 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6476 - val_accuracy: 0.8167 - val_loss: 1.1925 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6467 - val_accuracy: 0.8333 - val_loss: 1.1885 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6464 - val_accuracy: 0.8500 - val_loss: 1.1933 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6462 - val_accuracy: 0.8333 - val_loss: 1.1867 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6461 - val_accuracy: 0.8333 - val_loss: 1.1874 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6463 - val_accuracy: 0.8500 - val_loss: 1.1879 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6459 - val_accuracy: 0.8333 - val_loss: 1.1879 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6456 - val_accuracy: 0.8333 - val_loss: 1.1874 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6455 - val_accuracy: 0.8333 - val_loss: 1.1880 - learning_rate: 2.5000e-04\n",
            "Training Time Run 1: 106.84 seconds\n",
            "\n",
            "Inference Run 1\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step\n",
            "Inference Time Run 1: 10.27 seconds\n",
            "\n",
            "Training Run 2\n",
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 374ms/step - accuracy: 0.2313 - loss: 3.1211 - val_accuracy: 0.3167 - val_loss: 2.5409 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.5422 - loss: 1.8750 - val_accuracy: 0.4167 - val_loss: 2.0507 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.7811 - loss: 1.3793 - val_accuracy: 0.6333 - val_loss: 1.5863 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8976 - loss: 1.0185 - val_accuracy: 0.6500 - val_loss: 1.5897 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9006 - loss: 1.0064 - val_accuracy: 0.7167 - val_loss: 1.5174 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9633 - loss: 0.8239 - val_accuracy: 0.7500 - val_loss: 1.3646 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.7182 - val_accuracy: 0.8000 - val_loss: 1.2763 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6754 - val_accuracy: 0.8167 - val_loss: 1.2790 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6646 - val_accuracy: 0.8167 - val_loss: 1.2118 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6585 - val_accuracy: 0.8167 - val_loss: 1.2176 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6549 - val_accuracy: 0.8167 - val_loss: 1.2226 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.6528 - val_accuracy: 0.8167 - val_loss: 1.2164 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6533 - val_accuracy: 0.8167 - val_loss: 1.2114 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6510 - val_accuracy: 0.8167 - val_loss: 1.2260 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6497 - val_accuracy: 0.8167 - val_loss: 1.2199 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6488 - val_accuracy: 0.8167 - val_loss: 1.2164 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6485 - val_accuracy: 0.8167 - val_loss: 1.2145 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6481 - val_accuracy: 0.8167 - val_loss: 1.2119 - learning_rate: 2.5000e-04\n",
            "Training Time Run 2: 67.24 seconds\n",
            "\n",
            "Inference Run 2\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
            "Inference Time Run 2: 5.15 seconds\n",
            "\n",
            "Training Run 3\n",
            "Epoch 1/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 317ms/step - accuracy: 0.2476 - loss: 3.1800 - val_accuracy: 0.3667 - val_loss: 2.3526 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.6228 - loss: 1.7046 - val_accuracy: 0.6167 - val_loss: 1.6971 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7882 - loss: 1.2751 - val_accuracy: 0.5167 - val_loss: 1.8069 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8989 - loss: 1.0139 - val_accuracy: 0.7333 - val_loss: 1.4143 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9582 - loss: 0.8504 - val_accuracy: 0.7667 - val_loss: 1.3713 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9724 - loss: 0.7720 - val_accuracy: 0.7333 - val_loss: 1.3499 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9965 - loss: 0.7051 - val_accuracy: 0.8500 - val_loss: 1.2567 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6714 - val_accuracy: 0.8500 - val_loss: 1.2339 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6620 - val_accuracy: 0.8500 - val_loss: 1.2019 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6609 - val_accuracy: 0.8667 - val_loss: 1.2126 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6575 - val_accuracy: 0.8333 - val_loss: 1.2126 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6540 - val_accuracy: 0.8333 - val_loss: 1.1902 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6533 - val_accuracy: 0.8500 - val_loss: 1.2109 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6504 - val_accuracy: 0.8667 - val_loss: 1.2020 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.6503 - val_accuracy: 0.8500 - val_loss: 1.1871 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6483 - val_accuracy: 0.8333 - val_loss: 1.1880 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6476 - val_accuracy: 0.8500 - val_loss: 1.1961 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6469 - val_accuracy: 0.8500 - val_loss: 1.1885 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6469 - val_accuracy: 0.8500 - val_loss: 1.1893 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6459 - val_accuracy: 0.8500 - val_loss: 1.1864 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6459 - val_accuracy: 0.8500 - val_loss: 1.1894 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6459 - val_accuracy: 0.8500 - val_loss: 1.1882 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6457 - val_accuracy: 0.8500 - val_loss: 1.1900 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6454 - val_accuracy: 0.8500 - val_loss: 1.1904 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6452 - val_accuracy: 0.8500 - val_loss: 1.1873 - learning_rate: 2.5000e-04\n",
            "Training Time Run 3: 81.10 seconds\n",
            "\n",
            "Inference Run 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7cd6eecd7370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7cd6eecd7370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step\n",
            "Inference Time Run 3: 5.15 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "R187v4qiebm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_and_print_metrics(training_times, inference_times, val_accuracy_scores, val_loss_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLWUbD-mPxLn",
        "outputId": "df391190-64e2-4638-b21c-ea3199b9428f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Time: 85.06 seconds, Std Deviation 16.41 seconds\n",
            "Average Inference Time: 6.86 seconds, Std Deviation 2.41 seconds\n",
            "Average Accuracy: 0.8333, Std Dev: 0.0136\n",
            "Average Loss: 1.1957, Std Dev: 0.0115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Misclassified Labels"
      ],
      "metadata": {
        "id": "Vz5RmztGl3MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "misclassified_df = get_misclassified_dataframe(all_predictions, label_mapping, y_test)\n",
        "print(misclassified_df)"
      ],
      "metadata": {
        "id": "zrAEmSiGrjFS",
        "outputId": "eebf663b-c02c-4429-d6c0-5091beb76e84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Test Index True Label Predicted Label       File Name\n",
            "0           8    sedikit           orang  sedikit_01.npy\n",
            "1          22      makan           minum    makan_04.npy\n",
            "2          28      lihat           makan    lihat_04.npy\n",
            "3          34     kertas            main   kertas_01.npy\n",
            "4          49    gembira            buka  gembira_10.npy\n",
            "5          50       anak           orang     anak_03.npy\n",
            "6          57     dengar             ibu   dengar_04.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model C\n",
        "In contrast to the modifications explored in Model A and the hyperparameter tuning performed for Model B, Model C returned to the base model architecture. However, it retained the improved preprocessing steps implemented in Model A (addition of keypoint angles, coordinate standardization, and label smoothing). This approach was motivated by previous experiments suggesting that these preprocessing steps provided a significant performance boost independent of other architectural or training modifications.\n",
        "\n",
        "The Model C achieved the following results:\n",
        "\n",
        "* Average Training Time: 41.81 seconds ± 3.74 seconds\n",
        "* Average Inference Time: 5.16 seconds ± 0.00 seconds\n",
        "* Average Accuracy: 0.8000 ± 0.0471\n",
        "* Average Loss: 1.3508 ± 0.0349"
      ],
      "metadata": {
        "id": "CzOBWFVQP5zI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transformer_model(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Positional Encoding\n",
        "    positional_encoding = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(tf.range(input_shape[0]))\n",
        "    x = inputs + positional_encoding\n",
        "\n",
        "    # Transformer Encoder\n",
        "    for _ in range(4):  # Number of Transformer blocks\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x + attention_output)\n",
        "        ff_output = layers.Dense(241, activation='relu')(x)\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x + ff_output)\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "yXV1QAW-QdK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (113, 241)  # (n_frames, n_keypoints * n_coordinates)\n",
        "num_classes = 30\n",
        "val_accuracy_scores = []\n",
        "val_loss_scores = []\n",
        "training_times = []\n",
        "inference_times = []\n",
        "all_predictions = []\n",
        "\n",
        "# Run model training 3 times\n",
        "for i in range(3):\n",
        "    # Instantiate the model\n",
        "    transformer_model = create_transformer_model(input_shape, num_classes)\n",
        "\n",
        "    transformer_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    print(f\"Training Run {i+1}\")\n",
        "    start_time = time.time()  # Start the timer\n",
        "\n",
        "    history = transformer_model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=30,  # Replace with your actual number of epochs\n",
        "        batch_size=32,  # Replace with your batch size\n",
        "        callbacks=early_stopping\n",
        "    )\n",
        "\n",
        "    end_time = time.time()  # End the timer\n",
        "    elapsed_time = end_time - start_time\n",
        "    training_times.append(elapsed_time)\n",
        "    print(f\"Training Time Run {i+1}: {elapsed_time:.2f} seconds\\n\")\n",
        "\n",
        "    print(f\"Inference Run {i+1}\")\n",
        "    start_time = time.time()  # Start the timer\n",
        "\n",
        "    predictions = transformer_model.predict(X_test)  # Replace x_test with your test data\n",
        "\n",
        "    end_time = time.time()  # End the timer\n",
        "    elapsed_time = end_time - start_time\n",
        "    inference_times.append(elapsed_time)\n",
        "    print(f\"Inference Time Run {i+1}: {elapsed_time:.2f} seconds\\n\")\n",
        "    all_predictions.append(predictions)\n",
        "\n",
        "    val_accuracy_scores.append(history.history['val_accuracy'][-1])\n",
        "    val_loss_scores.append(history.history['val_loss'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MlTyO95QxfH",
        "outputId": "e96b7fa8-0a32-47e2-dd6a-f018887b6fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Run 1\n",
            "Epoch 1/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 325ms/step - accuracy: 0.2979 - loss: 2.8097 - val_accuracy: 0.5500 - val_loss: 1.8318\n",
            "Epoch 2/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8552 - loss: 1.1687 - val_accuracy: 0.7167 - val_loss: 1.5285\n",
            "Epoch 3/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9693 - loss: 0.8681 - val_accuracy: 0.7500 - val_loss: 1.4477\n",
            "Epoch 4/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9602 - loss: 0.8749 - val_accuracy: 0.8333 - val_loss: 1.3378\n",
            "Epoch 5/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9641 - loss: 0.8244 - val_accuracy: 0.7333 - val_loss: 1.5243\n",
            "Epoch 6/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9992 - loss: 0.7461 - val_accuracy: 0.8500 - val_loss: 1.3971\n",
            "Epoch 7/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6844 - val_accuracy: 0.8167 - val_loss: 1.4149\n",
            "Epoch 8/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9990 - loss: 0.6844 - val_accuracy: 0.8500 - val_loss: 1.3669\n",
            "Epoch 9/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9971 - loss: 0.6792 - val_accuracy: 0.8333 - val_loss: 1.3777\n",
            "Training Time Run 1: 38.41 seconds\n",
            "\n",
            "Inference Run 1\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step\n",
            "Inference Time Run 1: 5.16 seconds\n",
            "\n",
            "Training Run 2\n",
            "Epoch 1/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 308ms/step - accuracy: 0.2784 - loss: 2.7491 - val_accuracy: 0.5000 - val_loss: 1.9557\n",
            "Epoch 2/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.7729 - loss: 1.3683 - val_accuracy: 0.6833 - val_loss: 1.6665\n",
            "Epoch 3/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9443 - loss: 0.9358 - val_accuracy: 0.7500 - val_loss: 1.4792\n",
            "Epoch 4/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9561 - loss: 0.8619 - val_accuracy: 0.8000 - val_loss: 1.4107\n",
            "Epoch 5/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9893 - loss: 0.7458 - val_accuracy: 0.8000 - val_loss: 1.3698\n",
            "Epoch 6/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6944 - val_accuracy: 0.8500 - val_loss: 1.3332\n",
            "Epoch 7/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6747 - val_accuracy: 0.8333 - val_loss: 1.3015\n",
            "Epoch 8/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6677 - val_accuracy: 0.8500 - val_loss: 1.3057\n",
            "Epoch 9/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.6723 - val_accuracy: 0.8333 - val_loss: 1.3170\n",
            "Epoch 10/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9955 - loss: 0.6777 - val_accuracy: 0.7833 - val_loss: 1.4182\n",
            "Epoch 11/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9881 - loss: 0.7094 - val_accuracy: 0.8167 - val_loss: 1.2986\n",
            "Epoch 12/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.6713 - val_accuracy: 0.8500 - val_loss: 1.3202\n",
            "Epoch 13/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.6642 - val_accuracy: 0.8167 - val_loss: 1.2827\n",
            "Epoch 14/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6571 - val_accuracy: 0.8333 - val_loss: 1.3111\n",
            "Epoch 15/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.6537 - val_accuracy: 0.8333 - val_loss: 1.3079\n",
            "Epoch 16/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6510 - val_accuracy: 0.8333 - val_loss: 1.3000\n",
            "Epoch 17/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6494 - val_accuracy: 0.8333 - val_loss: 1.3100\n",
            "Epoch 18/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6483 - val_accuracy: 0.8333 - val_loss: 1.3015\n",
            "Training Time Run 2: 47.03 seconds\n",
            "\n",
            "Inference Run 2\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step\n",
            "Inference Time Run 2: 5.16 seconds\n",
            "\n",
            "Training Run 3\n",
            "Epoch 1/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 319ms/step - accuracy: 0.3024 - loss: 2.7373 - val_accuracy: 0.5167 - val_loss: 2.0699\n",
            "Epoch 2/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8124 - loss: 1.2577 - val_accuracy: 0.6000 - val_loss: 1.7169\n",
            "Epoch 3/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9575 - loss: 0.9221 - val_accuracy: 0.7000 - val_loss: 1.5771\n",
            "Epoch 4/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9864 - loss: 0.7954 - val_accuracy: 0.7167 - val_loss: 1.4171\n",
            "Epoch 5/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9893 - loss: 0.7544 - val_accuracy: 0.7167 - val_loss: 1.4254\n",
            "Epoch 6/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.7134 - val_accuracy: 0.7833 - val_loss: 1.3998\n",
            "Epoch 7/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.6776 - val_accuracy: 0.8167 - val_loss: 1.3777\n",
            "Epoch 8/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.6679 - val_accuracy: 0.7833 - val_loss: 1.3638\n",
            "Epoch 9/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6606 - val_accuracy: 0.7667 - val_loss: 1.3710\n",
            "Epoch 10/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6578 - val_accuracy: 0.7667 - val_loss: 1.3697\n",
            "Epoch 11/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6550 - val_accuracy: 0.7667 - val_loss: 1.3769\n",
            "Epoch 12/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6573 - val_accuracy: 0.7667 - val_loss: 1.3647\n",
            "Epoch 13/30\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6531 - val_accuracy: 0.7333 - val_loss: 1.3732\n",
            "Training Time Run 3: 40.00 seconds\n",
            "\n",
            "Inference Run 3\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step\n",
            "Inference Time Run 3: 5.16 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "CNulo3uDvB1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_and_print_metrics(training_times, inference_times, val_accuracy_scores, val_loss_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8eZDQw7RBJf",
        "outputId": "c4db4319-c37a-42a2-de1a-c0026f15b8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Time: 41.81 seconds, Std Deviation 3.74 seconds\n",
            "Average Inference Time: 5.16 seconds, Std Deviation 0.00 seconds\n",
            "Average Accuracy: 0.8000, Std Dev: 0.0471\n",
            "Average Loss: 1.3508, Std Dev: 0.0349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Misclassified Labels"
      ],
      "metadata": {
        "id": "0WKKhhODl5h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "misclassified_df = get_misclassified_dataframe(all_predictions, label_mapping, y_test)\n",
        "print(misclassified_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TSRDQeXRLMM",
        "outputId": "47c08041-08f7-4e62-9dd9-6723a3928322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Test Index True Label Predicted Label       File Name\n",
            "0            8    sedikit           orang  sedikit_01.npy\n",
            "1           14      orang           jalan    orang_02.npy\n",
            "2           15      orang            adik    orang_04.npy\n",
            "3           22      makan           minum    makan_04.npy\n",
            "4           28      lihat           makan    lihat_04.npy\n",
            "5           29      lihat            haus    lihat_07.npy\n",
            "6           34     kertas            main   kertas_01.npy\n",
            "7           39      jalan        keluarga    jalan_09.npy\n",
            "8           50       anak        keluarga     anak_03.npy\n",
            "9           56     dengar             ibu   dengar_02.npy\n",
            "10          57     dengar             ibu   dengar_04.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q dagshub\n",
        "\n",
        "from dagshub.notebook import save_notebook\n",
        "\n",
        "save_notebook(repo=\"Omdena/JakartaIndonesia_SignLanguageTranslation\", path=\"modeling\", branch=\"kenji_modeling\", commit_message=\"Add finalized Model Selection and Comparison notebook\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb9HqEXAITlO",
        "outputId": "56192d7d-fc67-4c7e-8a97-aa04997fff7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    }
  ]
}